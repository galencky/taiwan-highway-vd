{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/galenchen/taiwan-highway-vd-project?scriptVersionId=125816096\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"## Load the dataset and the packages\n* Suggest uploading the xml.gz files onto Kaggle so it doesn't fuck up the output storage.\n* Also, the package xmltodict have to be installed before anything happens.","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n!pip install xmltodict\nimport xmltodict\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport json\nfrom tqdm import tqdm\nimport urllib.request\nimport gzip\nfrom datetime import datetime, timedelta\nimport pytz\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-04-14T17:27:50.761925Z","iopub.execute_input":"2023-04-14T17:27:50.762433Z","iopub.status.idle":"2023-04-14T17:28:04.193494Z","shell.execute_reply.started":"2023-04-14T17:27:50.762393Z","shell.execute_reply":"2023-04-14T17:28:04.192036Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Collecting xmltodict\n  Downloading xmltodict-0.13.0-py2.py3-none-any.whl (10.0 kB)\nInstalling collected packages: xmltodict\nSuccessfully installed xmltodict-0.13.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"markdown","source":"## XML to JSON to DataFrame with pivoting to CSV pipeline","metadata":{}},{"cell_type":"code","source":"def get_vd(date, time, desired_vdid, realtime):\n    \n    if realtime == True:\n        directory = f\"VDLive_{time}.xml\"\n    else: directory = f\"/kaggle/input/highway-vd-data/{date}/{date}/VDLive_{time}.xml/VDLive_{time}.xml\"\n         \n    # Parse XML data into a dictionary\n    with open(directory) as xml_file:\n        data_dict = xmltodict.parse(xml_file.read())\n\n    # Convert dictionary to JSON\n    json_data = json.dumps(data_dict)\n    #print(\"XML file converted to JSON.\")\n\n    # Load the JSON data into a dictionary\n    data = json.loads(json_data)\n    #print(data)\n\n    # Get the desired VDID\n    # Iterate through the VDLives and find the one with the desired VDID\n    for vdlive in data[\"VDLiveList\"][\"VDLives\"][\"VDLive\"]:\n        if vdlive[\"VDID\"] == desired_vdid:\n            # Extract the data for the desired VDID\n            link_flows = vdlive[\"LinkFlows\"][\"LinkFlow\"]\n            status = vdlive[\"Status\"]\n            date_time = f'{date}_{time}'\n\n            # Print the VDID and its corresponding data\n            data= {\"VDID\": desired_vdid, \"LinkFlows\": link_flows, \"Status\": status,\n                   #\"DateTime\": date_time\n                  }\n            #print(f\"Detector {desired_vdid} found.\")\n            #print(data)\n            break\n\n    # Extract data from JSON and flatten into a list of rows\n    rows = []\n    vdid = data['VDID']\n    date_time = f'{date}_{time}'\n    link_id = data['LinkFlows']['LinkID']\n\n    # Situation 1: 'Lane' key is present in the 'Lanes' dictionary\n    if 'Lane' in data['LinkFlows']['Lanes']:\n        lanes = data['LinkFlows']['Lanes']['Lane']\n        if isinstance(lanes, dict):\n            # If 'Lane' is a dictionary, convert it to a list with a single element\n            lanes = [lanes]\n        for lane in lanes:\n            lane_id = lane['LaneID']\n            lane_type = lane['LaneType']\n            lane_speed = lane['Speed']\n            occupancy = lane['Occupancy']\n            for vehicle in lane['Vehicles']['Vehicle']:\n                vehicle_type = vehicle['VehicleType']\n                volume = vehicle['Volume']\n                speed = vehicle['Speed']\n                rows.append([date_time, vdid, link_id, lane_id,\n                             lane_type, lane_speed, occupancy, \n                             vehicle_type, volume, speed])\n\n    # Situation 2: 'Lane' key is not present in the 'Lanes' dictionary\n    elif 'Lane' in data['LinkFlows']['Lanes']['Lane']:\n        lane = data['LinkFlows']['Lanes']['Lane']\n        lane_id = lane['LaneID']\n        lane_type = lane['LaneType']\n        lane_speed = lane['Speed']\n        occupancy = lane['Occupancy']\n        for vehicle in lane['Vehicles']['Vehicle']:\n            vehicle_type = vehicle['VehicleType']\n            volume = vehicle['Volume']\n            speed = vehicle['Speed']\n            rows.append([date_time, vdid, link_id, lane_id,\n                         lane_type, lane_speed, occupancy,\n                         vehicle_type, volume, speed])\n         \n    return rows \n\n\ndef get_vds(date, desired_vdid, start_time, end_time, realtime):\n\n    # Convert start_time and end_time to integers\n    start_time2 = int(start_time)\n    str_end_time = end_time\n    end_time = int(end_time)\n\n    # Convert start_time and end_time to minutes\n    start_time_minutes = (start_time2 // 100) * 60 + (start_time2 % 100)\n    end_time_minutes = (end_time // 100) * 60 + (end_time % 100)\n    total = end_time_minutes - start_time_minutes + 1\n\n    # Create an empty list to store the results\n    results = []\n    missing = []\n    i = 0\n    current_time = start_time\n\n    # Loop through the function multiple times and append the result to the list\n    with tqdm(total=total) as pbar:\n        while i < total:\n            if realtime == True:\n                download_xml(date, current_time)\n            if file_exist==True: ##########\n                result = get_vd(date, current_time, desired_vdid, realtime)\n                results.extend(result)\n                if realtime == True:\n                    os.remove(f\"/kaggle/working/VDLive_{current_time}.xml\")\n            else: missing.append(str(current_time))\n            pbar.update(1)\n            i += 1\n\n            if int(current_time) % 100 == 59:\n                current_time = str(int(current_time)+41)\n            else:\n                current_time = str(int(current_time)+1)\n            \n            if int(current_time)<10:\n                current_time = f\"000{current_time}\"\n            elif int(current_time)<100:\n                current_time = f\"00{current_time}\"\n            elif int(current_time)<1000:\n                current_time = f\"0{current_time}\"\n            else:\n                current_time = current_time\n\n    #print(results)\n\n    # Create a pandas DataFrame from the rows list\n    df = pd.DataFrame(results, columns=['DateTime', 'VDID', 'LinkID',\n                                        'LaneID', 'LaneType',\n                                        'LaneSpeed', 'Occupancy',\n                                        'VehicleType', 'Volume', 'Speed'])\n    #pivot dataframe according to vehicle\n    df = df.pivot(index=['DateTime', 'VDID', 'LinkID', 'LaneID',\n                     'LaneType', 'LaneSpeed', 'Occupancy'],\n              columns='VehicleType',\n              values=['Volume', 'Speed'])\n    df.columns = ['_'.join(col).strip() for col in df.columns.values]\n    df = df.reset_index()\n    df = df.reindex(columns=['DateTime', 'VDID', #'LinkID', \n                             'LaneID',#'LaneType',\n                             'LaneSpeed', 'Occupancy',\n                             'Volume_S', 'Speed_S', 'Volume_L', 'Speed_L', 'Volume_T', 'Speed_T'])\n    \n    #pivot the dataframe according to lane\n    df = df.pivot_table(index=['DateTime', 'VDID'], columns='LaneID', values=['LaneSpeed', 'Occupancy', 'Volume_S', 'Speed_S', 'Volume_L', 'Speed_L', 'Volume_T', 'Speed_T']).reset_index()\n    #flatten the column names\n    df.columns = ['_'.join(str(col).strip() for col in tup) for tup in df.columns.values]\n\n    #Save to CSV\n    filename = f'{date}_{desired_vdid}_{start_time}_{str_end_time}'\n    df.to_csv(f'{filename}.csv', index=False)\n    print(f'{filename}.csv has been saved in /kaggle/working.')\n    print(f'missing files = {missing}')\n    #display(df)","metadata":{"execution":{"iopub.status.busy":"2023-04-14T17:28:04.196651Z","iopub.execute_input":"2023-04-14T17:28:04.197123Z","iopub.status.idle":"2023-04-14T17:28:04.227243Z","shell.execute_reply.started":"2023-04-14T17:28:04.19708Z","shell.execute_reply":"2023-04-14T17:28:04.225734Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## Realtime downloading and conversion pipeline\n\nDownload xml.gz file, decompress into xml file, then delete the xml.gz, then feed the xml into get_vd, then delete the xml after data is analyzed.","metadata":{}},{"cell_type":"code","source":"file_exist = False\n\ndef download_xml(date, current_time):\n    global file_exist\n    \n    file_exist = False\n    \n    url = f'https://tisvcloud.freeway.gov.tw/history/motc20/VD/{date}/VDLive_{current_time}.xml.gz'\n    filename = f'VDLive_{current_time}.xml.gz'\n\n    # Download the file\n    if os.path.isfile(f\"/kaggle/working/VDLive_{current_time}.xml.gz\"):\n        #print(f'File {filename} already exists')\n        file_exist = True\n    else:\n        urllib.request.urlretrieve(url, filename)\n        if urllib.request.urlopen(url).getcode() == 404:\n            #print(f'File {filename} does not exist')\n            os.remove(filename)\n        elif os.path.getsize(filename) == 0:\n            #print(f'File {filename} has no file size')\n            os.remove(filename)\n        else:\n            file_exist = True\n            #print(f\"File {filename} downloaded\")\n\n    if file_exist:\n        #file decompression        \n        if os.path.isfile(f\"/kaggle/working/VDLive_{current_time}.xml.gz\"):\n            # Step 1: Open the compressed XML file and read its contents\n            with gzip.open(f'/kaggle/working/VDLive_{current_time}.xml.gz', 'rb') as f:\n                xml_data = f.read()\n\n            # Step 2: Create a new file with the same name as the compressed XML file, but with the .xml extension\n            xml_file_path = f'VDLive_{current_time}.xml'\n\n            # Step 3: Write the uncompressed XML data to the new file\n            with open(xml_file_path, 'wb') as f:\n                f.write(xml_data)\n\n            # Step 4: Verify that the new file was created successfully\n            if os.path.exists(xml_file_path):\n                #print(f'{xml_file_path} was created successfully!')\n                os.remove(f\"/kaggle/working/VDLive_{current_time}.xml.gz\")\n            else:\n                print(f'Error: {xml_file_path} was not created.')\n        else:\n            print(f\"Error: VDLive_{current_time}.xml.gz not found.\")\n","metadata":{"execution":{"iopub.status.busy":"2023-04-14T17:28:04.22926Z","iopub.execute_input":"2023-04-14T17:28:04.230091Z","iopub.status.idle":"2023-04-14T17:28:04.247286Z","shell.execute_reply.started":"2023-04-14T17:28:04.23003Z","shell.execute_reply":"2023-04-14T17:28:04.245957Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"## The Function.\n### get_vds(date, detector, start time, end time, realtime file download)","metadata":{}},{"cell_type":"code","source":"#get_vds(\"20230319\", \"VD-N3-N-166.688-M-RS\", \"1330\", \"1339\", True )\n#get_vds(\"20230315\", \"VD-N1-S-371.010-M-Loop\", \"1300\", \"1304\", True )","metadata":{"execution":{"iopub.status.busy":"2023-04-14T17:28:04.249976Z","iopub.execute_input":"2023-04-14T17:28:04.250445Z","iopub.status.idle":"2023-04-14T17:28:04.263014Z","shell.execute_reply.started":"2023-04-14T17:28:04.250407Z","shell.execute_reply":"2023-04-14T17:28:04.26156Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"## Acquire time so the script does automatic daily updates for yesterday.","metadata":{}},{"cell_type":"code","source":"# Set the time zone to GMT+8\ntz = pytz.timezone('Asia/Taipei')\n# Get the current time in GMT+8 time zone\nnow = datetime.now(tz)\n# Subtract one day to get yesterday's date\nyesterday = now - timedelta(days=1)\n# Format yesterday's date as YYYYMMDD\nyesterday_str = yesterday.strftime('%Y%m%d')\n\nprint(yesterday_str)\n","metadata":{"execution":{"iopub.status.busy":"2023-04-14T17:28:04.264559Z","iopub.execute_input":"2023-04-14T17:28:04.265691Z","iopub.status.idle":"2023-04-14T17:28:04.332455Z","shell.execute_reply.started":"2023-04-14T17:28:04.26564Z","shell.execute_reply":"2023-04-14T17:28:04.331088Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"20230414\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Download multiple DATE x VDID loop","metadata":{}},{"cell_type":"code","source":"date_list = [yesterday_str]\nvdid_list = [\"VD-N1-S-369.007-M-Loop\", \"VD-N1-S-369.400-M-Loop\", \"VD-N1-S-370.000-M-Loop\", \"VD-N1-S-371.010-M-Loop\"]\nstart_time = \"0000\"\nend_time = \"2359\"\nrealtime = True\n\nfor date in date_list:\n    for vdid in vdid_list:\n        get_vds(date, vdid, start_time, end_time, realtime)\n        \nprint(\"All tasks in the loop were completed.\")","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-04-14T17:28:04.334117Z","iopub.execute_input":"2023-04-14T17:28:04.334932Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":" 17%|█▋        | 251/1440 [10:00<1:21:23,  4.11s/it]","output_type":"stream"}]},{"cell_type":"markdown","source":"import os\n\npath = \"/kaggle/working/20230413_VD-N1-S-369.007-M-Loop_0000_2359.csv\"\nos.remove(path)","metadata":{"execution":{"iopub.status.busy":"2023-04-14T17:27:26.700215Z","iopub.execute_input":"2023-04-14T17:27:26.700682Z","iopub.status.idle":"2023-04-14T17:27:26.70702Z","shell.execute_reply.started":"2023-04-14T17:27:26.700647Z","shell.execute_reply":"2023-04-14T17:27:26.705707Z"}}}]}